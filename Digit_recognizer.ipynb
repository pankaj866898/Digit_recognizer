{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6BexKIi0E_8o"
      },
      "outputs": [],
      "source": [
        "# pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data to fit the model (samples, width, height, channels)\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# One-hot encode target values\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200)\n",
        "\n",
        "# Evaluate the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'Accuracy: {scores[1] * 100}%')\n",
        "\n",
        "# Save the model\n",
        "model.save('digit_recognizer.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAWD0f4_FHqq",
        "outputId": "e1c4cf18-79f0-4cad-e1de-666a83940a81"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "Epoch 1/10\n",
            "300/300 [==============================] - 7s 6ms/step - loss: 0.2552 - accuracy: 0.9260 - val_loss: 0.0688 - val_accuracy: 0.9795\n",
            "Epoch 2/10\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 0.0631 - accuracy: 0.9806 - val_loss: 0.0419 - val_accuracy: 0.9869\n",
            "Epoch 3/10\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 0.0444 - accuracy: 0.9862 - val_loss: 0.0380 - val_accuracy: 0.9887\n",
            "Epoch 4/10\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0333 - accuracy: 0.9899 - val_loss: 0.0294 - val_accuracy: 0.9912\n",
            "Epoch 5/10\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.0324 - val_accuracy: 0.9898\n",
            "Epoch 6/10\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.0312 - val_accuracy: 0.9900\n",
            "Epoch 7/10\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0293 - val_accuracy: 0.9914\n",
            "Epoch 8/10\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.0320 - val_accuracy: 0.9903\n",
            "Epoch 9/10\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0336 - val_accuracy: 0.9906\n",
            "Epoch 10/10\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0341 - val_accuracy: 0.9905\n",
            "Accuracy: 99.04999732971191%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and use the model for predictions (optional)\n",
        "model = tf.keras.models.load_model('digit_recognizer.h5')\n",
        "predictions = model.predict(x_test)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUHyYvFSFJlA",
        "outputId": "f76ae222-1f93-4918-f225-2747fe3295a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "[[4.1937613e-11 4.6558965e-10 6.3021020e-08 ... 9.9999642e-01\n",
            "  7.8607265e-10 1.6389569e-09]\n",
            " [1.4654108e-11 1.8768520e-09 1.0000000e+00 ... 3.5986472e-18\n",
            "  2.3281651e-13 7.4427170e-16]\n",
            " [1.8677312e-08 9.9960655e-01 3.7627467e-07 ... 8.7142116e-06\n",
            "  1.0646189e-05 1.3095837e-07]\n",
            " ...\n",
            " [3.7706323e-17 1.8567162e-10 5.4097884e-14 ... 3.2469680e-10\n",
            "  3.0149935e-11 4.6036627e-10]\n",
            " [3.6706280e-09 1.1154127e-11 3.8387630e-11 ... 4.7986246e-14\n",
            "  1.6597404e-06 4.8185965e-12]\n",
            " [2.7316668e-10 5.7524818e-12 4.1354919e-09 ... 1.2448612e-16\n",
            "  2.9352842e-09 4.6752139e-14]]\n"
          ]
        }
      ]
    }
  ]
}